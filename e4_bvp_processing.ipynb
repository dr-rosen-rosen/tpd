{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842fa3ce-cbc8-4855-91d1-863f722b2e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heartpy as hp\n",
    "import sqlalchemy as sa\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "355c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'picu' # 'picu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0bbc5f-30ef-4ee3-94dd-a235ff07c13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up DB connection\n",
    "db_pw = 'LetMeIn21'\n",
    "db_user = 'postgres'\n",
    "db_name = 'e4_'+ project\n",
    "port = '5432'\n",
    "db_string = 'postgresql://'+db_user+':'+db_pw+'@localhost:'+port+'/'+db_name\n",
    "engine = sa.create_engine(db_string)\n",
    "metadata_obj = sa.MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c114f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def filter_bvp(raw):\n",
    "    # funciton takes a vector of bvp values, finds segements w/ missing data\n",
    "    # and sets those intervals to 0\n",
    "    # This is based on (/is) example for pyHeart\n",
    "\n",
    "    # raw = df['bvp'].values\n",
    "    \n",
    "    mx = np.max(raw)\n",
    "    mn = np.min(raw)\n",
    "    global_range = mx - mn\n",
    "    windowsize = 100\n",
    "    filtered = []\n",
    "\n",
    "    for i in range(len(raw) // windowsize):\n",
    "        start = i*windowsize\n",
    "        end = (i + 1)*windowsize\n",
    "        sliced = raw[start:end]\n",
    "        rng = np.max(sliced) - np.min(sliced)\n",
    "        \n",
    "        if ((rng >= (0.5 * global_range))\n",
    "            or\n",
    "            (np.max(sliced) >= 0.9 * mx)\n",
    "            or\n",
    "            (np.min(sliced) <= mn + (0.1 + mn))):\n",
    "            \n",
    "            for x in sliced:\n",
    "                filtered.append(0)\n",
    "        else:\n",
    "            for x in sliced:\n",
    "                filtered.append(x)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1e34e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shift_day</th>\n",
       "      <th>study_member_id</th>\n",
       "      <th>date</th>\n",
       "      <th>e4_id</th>\n",
       "      <th>rtls_id</th>\n",
       "      <th>sociometric_id</th>\n",
       "      <th>am_or_pm</th>\n",
       "      <th>rhythm_badge_num</th>\n",
       "      <th>code_event</th>\n",
       "      <th>start_time</th>\n",
       "      <th>shift_chunk</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>task_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pilot_Day_6</td>\n",
       "      <td>2678.0</td>\n",
       "      <td>2020-10-15 20:00:00-04:00</td>\n",
       "      <td>A025B3</td>\n",
       "      <td>404455.0</td>\n",
       "      <td>1102</td>\n",
       "      <td>am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-16 07:00:00-04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pilot_Day_6</td>\n",
       "      <td>2325.0</td>\n",
       "      <td>2020-10-15 20:00:00-04:00</td>\n",
       "      <td>A02827</td>\n",
       "      <td>403680.0</td>\n",
       "      <td>1098</td>\n",
       "      <td>am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-16 07:00:00-04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pilot_Day_6</td>\n",
       "      <td>2858.0</td>\n",
       "      <td>2020-10-15 20:00:00-04:00</td>\n",
       "      <td>A02823</td>\n",
       "      <td>403682.0</td>\n",
       "      <td>1107</td>\n",
       "      <td>am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-16 07:00:00-04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pilot_Day_6</td>\n",
       "      <td>1475.0</td>\n",
       "      <td>2020-10-15 20:00:00-04:00</td>\n",
       "      <td>A0280D</td>\n",
       "      <td>296717.0</td>\n",
       "      <td>1081</td>\n",
       "      <td>am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-16 07:00:00-04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shift_01</td>\n",
       "      <td>2269.0</td>\n",
       "      <td>2020-10-29 20:00:00-04:00</td>\n",
       "      <td>A025B3</td>\n",
       "      <td>404455.0</td>\n",
       "      <td>1102</td>\n",
       "      <td>am</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-10-30 07:00:00-04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     shift_day  study_member_id                       date   e4_id   rtls_id   \n",
       "0  Pilot_Day_6           2678.0  2020-10-15 20:00:00-04:00  A025B3  404455.0  \\\n",
       "1  Pilot_Day_6           2325.0  2020-10-15 20:00:00-04:00  A02827  403680.0   \n",
       "2  Pilot_Day_6           2858.0  2020-10-15 20:00:00-04:00  A02823  403682.0   \n",
       "3  Pilot_Day_6           1475.0  2020-10-15 20:00:00-04:00  A0280D  296717.0   \n",
       "4     Shift_01           2269.0  2020-10-29 20:00:00-04:00  A025B3  404455.0   \n",
       "\n",
       "  sociometric_id am_or_pm  rhythm_badge_num  code_event   \n",
       "0           1102       am               NaN         NaN  \\\n",
       "1           1098       am               NaN         NaN   \n",
       "2           1107       am               NaN         NaN   \n",
       "3           1081       am               NaN         NaN   \n",
       "4           1102       am               NaN         1.0   \n",
       "\n",
       "                  start_time  shift_chunk  duration_min  task_num  \n",
       "0  2020-10-16 07:00:00-04:00          0.0         240.0         1  \n",
       "1  2020-10-16 07:00:00-04:00          0.0         240.0         1  \n",
       "2  2020-10-16 07:00:00-04:00          0.0         240.0         1  \n",
       "3  2020-10-16 07:00:00-04:00          0.0         240.0         1  \n",
       "4  2020-10-30 07:00:00-04:00          0.0         240.0         4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in task list\n",
    "t = sa.Table(\"task_list\", metadata_obj, autoload_with=engine)\n",
    "s = sa.select(t)\n",
    "with engine.connect() as conn:\n",
    "    rp = conn.execute(s)\n",
    "    task_list_df = pd.DataFrame(rp.fetchall())\n",
    "    task_list_df.columns = rp.keys()\n",
    "if project == 'hera':\n",
    "    task_list_df = task_list_df[['task_num','duration_min','start_time','cdr','fe','ms1','ms2']]\n",
    "    task_list_df = task_list_df.melt(id_vars=['task_num','duration_min','start_time'], value_vars=['cdr','fe','ms1','ms2'])\n",
    "    task_list_df.sort_values(by=['task_num'],inplace=True)\n",
    "    task_list_df.drop(columns = 'variable', inplace=True)\n",
    "    task_list_df.rename(columns={'value':'e4_id'}, inplace=True)\n",
    "    task_list_df.dropna(inplace=True)\n",
    "    task_list_df = task_list_df[task_list_df.e4_id != 'NA']\n",
    "task_list_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45d627bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting all days for which there are data in a given table\n",
    "\n",
    "def get_days(t,s,engine):\n",
    "    with engine.begin() as conn:\n",
    "        rp = conn.execute(s)\n",
    "        dates = pd.DataFrame(rp.fetchall())\n",
    "        dates.columns = rp.keys()\n",
    "        dates = dates['time_stamp'].tolist()\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a61b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a010ab_bvp\n",
      "2019-10-18\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mrosen44\\Documents\\Data_Analysis_Local\\tpd\\e4_bvp_processing.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mwith\u001b[39;00m engine\u001b[39m.\u001b[39mbegin() \u001b[39mas\u001b[39;00m conn:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     rp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mexecute(s)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     bvp_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(rp\u001b[39m.\u001b[39;49mfetchall())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bvp_df\u001b[39m.\u001b[39mempty:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         bvp_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m rp\u001b[39m.\u001b[39mkeys()\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:782\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    781\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 782\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[0;32m    783\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    784\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    785\u001b[0m         data,\n\u001b[0;32m    786\u001b[0m         columns,\n\u001b[0;32m    787\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    788\u001b[0m         dtype,\n\u001b[0;32m    789\u001b[0m     )\n\u001b[0;32m    790\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    791\u001b[0m         arrays,\n\u001b[0;32m    792\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    795\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    796\u001b[0m     )\n\u001b[0;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:498\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[1;32m--> 498\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    499\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:840\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    837\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[0;32m    838\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 840\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[0;32m    841\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:940\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m--> 940\u001b[0m     contents \u001b[39m=\u001b[39m convert_object_array(contents, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    942\u001b[0m \u001b[39mreturn\u001b[39;00m contents, columns\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:1067\u001b[0m, in \u001b[0;36mconvert_object_array\u001b[1;34m(content, dtype, dtype_backend, coerce_float)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             arr \u001b[39m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[0;32m   1065\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\n\u001b[1;32m-> 1067\u001b[0m arrays \u001b[39m=\u001b[39m [convert(arr) \u001b[39mfor\u001b[39;49;00m arr \u001b[39min\u001b[39;49;00m content]\n\u001b[0;32m   1069\u001b[0m \u001b[39mreturn\u001b[39;00m arrays\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:1067\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1063\u001b[0m             arr \u001b[39m=\u001b[39m maybe_cast_to_datetime(arr, dtype)\n\u001b[0;32m   1065\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\n\u001b[1;32m-> 1067\u001b[0m arrays \u001b[39m=\u001b[39m [convert(arr) \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m content]\n\u001b[0;32m   1069\u001b[0m \u001b[39mreturn\u001b[39;00m arrays\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:1040\u001b[0m, in \u001b[0;36mconvert_object_array.<locals>.convert\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   1039\u001b[0m         \u001b[39m# i.e. maybe_convert_objects didn't convert\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m         arr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(arr)\n\u001b[0;32m   1041\u001b[0m         \u001b[39mif\u001b[39;00m dtype_backend \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   1042\u001b[0m             arr \u001b[39m=\u001b[39m StringDtype()\u001b[39m.\u001b[39mconstruct_array_type()\u001b[39m.\u001b[39m_from_sequence(arr)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1178\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m   1175\u001b[0m \u001b[39m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m \u001b[39m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[39m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[1;32m-> 1178\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmaybe_convert_objects(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   1179\u001b[0m     value,\n\u001b[0;32m   1180\u001b[0m     \u001b[39m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[0;32m   1181\u001b[0m     \u001b[39m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[0;32m   1182\u001b[0m     convert_numeric\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1183\u001b[0m     convert_period\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1184\u001b[0m     convert_interval\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1185\u001b[0m     convert_timedelta\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1186\u001b[0m     convert_datetime\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1187\u001b[0m     dtype_if_all_nat\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mM8[ns]\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1188\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2567\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:339\u001b[0m, in \u001b[0;36mDatetimeIndex.__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    336\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_simple_new(data, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 339\u001b[0m dtarr \u001b[39m=\u001b[39m DatetimeArray\u001b[39m.\u001b[39;49m_from_sequence_not_strict(\n\u001b[0;32m    340\u001b[0m     data,\n\u001b[0;32m    341\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    342\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    343\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m    344\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[0;32m    345\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m    346\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m    347\u001b[0m     ambiguous\u001b[39m=\u001b[39;49mambiguous,\n\u001b[0;32m    348\u001b[0m )\n\u001b[0;32m    349\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m copy \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (Index, ABCSeries)):\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:333\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m         \u001b[39m# DatetimeTZDtype\u001b[39;00m\n\u001b[0;32m    331\u001b[0m         unit \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39munit\n\u001b[1;32m--> 333\u001b[0m subarr, tz, inferred_freq \u001b[39m=\u001b[39m _sequence_to_dt64ns(\n\u001b[0;32m    334\u001b[0m     data,\n\u001b[0;32m    335\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    336\u001b[0m     tz\u001b[39m=\u001b[39;49mtz,\n\u001b[0;32m    337\u001b[0m     dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m    338\u001b[0m     yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m    339\u001b[0m     ambiguous\u001b[39m=\u001b[39;49mambiguous,\n\u001b[0;32m    340\u001b[0m     out_unit\u001b[39m=\u001b[39;49munit,\n\u001b[0;32m    341\u001b[0m )\n\u001b[0;32m    342\u001b[0m \u001b[39m# We have to call this again after possibly inferring a tz above\u001b[39;00m\n\u001b[0;32m    343\u001b[0m _validate_tz_from_dtype(dtype, tz, explicit_tz_none)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2057\u001b[0m, in \u001b[0;36m_sequence_to_dt64ns\u001b[1;34m(data, copy, tz, dayfirst, yearfirst, ambiguous, out_unit)\u001b[0m\n\u001b[0;32m   2053\u001b[0m     \u001b[39mreturn\u001b[39;00m i8data\u001b[39m.\u001b[39mview(DT64NS_DTYPE), tz, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2054\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2055\u001b[0m     \u001b[39m# data comes back here as either i8 to denote UTC timestamps\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m     \u001b[39m#  or M8[ns] to denote wall times\u001b[39;00m\n\u001b[1;32m-> 2057\u001b[0m     data, inferred_tz \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m   2058\u001b[0m         data,\n\u001b[0;32m   2059\u001b[0m         dayfirst\u001b[39m=\u001b[39;49mdayfirst,\n\u001b[0;32m   2060\u001b[0m         yearfirst\u001b[39m=\u001b[39;49myearfirst,\n\u001b[0;32m   2061\u001b[0m         allow_object\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   2062\u001b[0m     )\n\u001b[0;32m   2063\u001b[0m     \u001b[39mif\u001b[39;00m tz \u001b[39mand\u001b[39;00m inferred_tz:\n\u001b[0;32m   2064\u001b[0m         \u001b[39m#  two timezones: convert to intended from base UTC repr\u001b[39;00m\n\u001b[0;32m   2065\u001b[0m         \u001b[39massert\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi8\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2189\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[0;32m   2177\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m tslib\u001b[39m.\u001b[39marray_to_datetime(\n\u001b[0;32m   2178\u001b[0m     data,\n\u001b[0;32m   2179\u001b[0m     errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2182\u001b[0m     yearfirst\u001b[39m=\u001b[39myearfirst,\n\u001b[0;32m   2183\u001b[0m )\n\u001b[0;32m   2185\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2186\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2187\u001b[0m     \u001b[39m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2188\u001b[0m     \u001b[39m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[1;32m-> 2189\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39;49mview(\u001b[39m\"\u001b[39;49m\u001b[39mi8\u001b[39;49m\u001b[39m\"\u001b[39;49m), tz_parsed\n\u001b[0;32m   2190\u001b[0m \u001b[39melif\u001b[39;00m is_datetime64_dtype(result):\n\u001b[0;32m   2191\u001b[0m     \u001b[39m# returning M8[ns] denotes wall-times; since tz is None\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m     \u001b[39m#  the distinction is a thin one\u001b[39;00m\n\u001b[0;32m   2193\u001b[0m     \u001b[39mreturn\u001b[39;00m result, tz_parsed\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NASA all day data\n",
    "\n",
    "# Get list of all bvp tables\n",
    "metadata_obj.reflect(engine)\n",
    "bvp_tables = [t for t in metadata_obj.tables.keys() if 'bvp' in t] # only works if there are no modified eda tables\n",
    "#eda_tables = ['a0189a_eda']\n",
    "for tbl in bvp_tables:\n",
    "    # get all of the days for which there are data\n",
    "    t = sa.Table(tbl, metadata_obj, autoload_with=engine)\n",
    "    s = sa.select(sa.cast(t.c.time_stamp, sa.types.Date)).distinct()\n",
    "    print(tbl)\n",
    "    dates = get_days(t,s,engine)\n",
    "    for d in dates:\n",
    "        print(d)\n",
    "        # get all the data for that day\n",
    "        #t = sa.Table(tbl,metadata_obj, autoload_with=engine)\n",
    "        s = sa.select(t).where(\n",
    "            sa.cast(t.c.time_stamp,sa.types.DATE) == d\n",
    "        )\n",
    "        with engine.begin() as conn:\n",
    "            rp = conn.execute(s)\n",
    "            bvp_df = pd.DataFrame(rp.fetchall())\n",
    "            if not bvp_df.empty:\n",
    "                bvp_df.columns = rp.keys()\n",
    "                print(len(bvp_df))\n",
    "                raw_ibi_row_cnt = len(bvp_df)\n",
    "                # creates values at 30 second intervals (with a 1 min window)\n",
    "                wd,m = hp.process_segmentwise(bvp_df.bvp.values,sample_rate = 64, segment_width = 60, \n",
    "                                                segment_overlap = .5, replace_outliers = True, \n",
    "                                                outlier_method = 'iqr', mode = 'full')\n",
    "                m = pd.DataFrame.from_dict(m)\n",
    "                m['start_ix'], m['end_ix'] = zip(*m.segment_indices)\n",
    "                m['time_stamp'] = m.end_ix.map(dict(zip(bvp_df.index,bvp_df.time_stamp)))\n",
    "                m['sdsd'] = m.sdsd.astype('float')\n",
    "                m.drop(['start_ix','end_ix','segment_indices'], axis=1, inplace=True)\n",
    "                dtype_dict = {\n",
    "                    'ibi':sa.types.FLOAT(),\n",
    "                    'sdnn': sa.types.FLOAT(),\n",
    "                    'sdsd': sa.types.FLOAT(),\n",
    "                    'rmssd': sa.types.FLOAT(),\n",
    "                    'pnn20': sa.types.FLOAT(),\n",
    "                    'pnn50': sa.types.FLOAT(),\n",
    "                    'hr_mad': sa.types.FLOAT(),\n",
    "                    'sd1':sa.types.FLOAT(),\n",
    "                    'sd2': sa.types.FLOAT(),\n",
    "                    's': sa.types.FLOAT(),\n",
    "                    'sd1/sd2': sa.types.FLOAT(),\n",
    "                    'breathingrate': sa.types.FLOAT(),\n",
    "                    'time_stamp': sa.types.TIMESTAMP(timezone=True)\n",
    "                }\n",
    "                print(tbl.replace('_bvp','')+'_hpy_rolling')\n",
    "                m.to_sql(name=tbl.replace('_bvp','')+'_hpy_rolling',\n",
    "                    con = conn,\n",
    "                    if_exists = 'append',\n",
    "                    index = False,\n",
    "                    dtype = dtype_dict,\n",
    "                    method = 'multi')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf0e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 A025B3...\n",
      "868096\n"
     ]
    },
    {
     "ename": "CompileError",
     "evalue": "Unconsumed column names: sd1/sd2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCompileError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mrosen44\\Documents\\Data_Analysis_Local\\tpd\\e4_bvp_processing.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m t \u001b[39m=\u001b[39m sa\u001b[39m.\u001b[39mTable(\u001b[39m\"\u001b[39m\u001b[39mcardiac_ind_summary\u001b[39m\u001b[39m\"\u001b[39m, metadata_obj, autoload_with\u001b[39m=\u001b[39mengine)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m s \u001b[39m=\u001b[39m sa\u001b[39m.\u001b[39minsert(t)\u001b[39m.\u001b[39mvalues(m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m conn\u001b[39m.\u001b[39;49mexecute(s)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# save figs for QC\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m#lab = 'task_num_'+str(row['task_num'])+'_'+row['e4_id'].lower()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m#hp.plotter(wd,m, figsize = (12,6),title = lab, show=False).savefig('bvp_plots/'+lab+'.png')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mrosen44/Documents/Data_Analysis_Local/tpd/e4_bvp_processing.ipynb#X10sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m#hp.plot_poincare(wd,m, title = lab, show=False).savefig('bvp_plots/'+lab+'poincare.png')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1413\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1413\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[0;32m   1414\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1415\u001b[0m         distilled_parameters,\n\u001b[0;32m   1416\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[0;32m   1417\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:483\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    482\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[1;32m--> 483\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[0;32m    484\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[0;32m    485\u001b[0m     )\n\u001b[0;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    487\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1629\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1621\u001b[0m schema_translate_map \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1622\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mschema_translate_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1623\u001b[0m )\n\u001b[0;32m   1625\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[0;32m   1626\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[0;32m   1627\u001b[0m )\n\u001b[1;32m-> 1629\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39;49m_compile_w_cache(\n\u001b[0;32m   1630\u001b[0m     dialect\u001b[39m=\u001b[39;49mdialect,\n\u001b[0;32m   1631\u001b[0m     compiled_cache\u001b[39m=\u001b[39;49mcompiled_cache,\n\u001b[0;32m   1632\u001b[0m     column_keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[0;32m   1633\u001b[0m     for_executemany\u001b[39m=\u001b[39;49mfor_executemany,\n\u001b[0;32m   1634\u001b[0m     schema_translate_map\u001b[39m=\u001b[39;49mschema_translate_map,\n\u001b[0;32m   1635\u001b[0m     linting\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mcompiler_linting \u001b[39m|\u001b[39;49m compiler\u001b[39m.\u001b[39;49mWARN_LINTING,\n\u001b[0;32m   1636\u001b[0m )\n\u001b[0;32m   1637\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_execute_context(\n\u001b[0;32m   1638\u001b[0m     dialect,\n\u001b[0;32m   1639\u001b[0m     dialect\u001b[39m.\u001b[39mexecution_ctx_cls\u001b[39m.\u001b[39m_init_compiled,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     cache_hit\u001b[39m=\u001b[39mcache_hit,\n\u001b[0;32m   1648\u001b[0m )\n\u001b[0;32m   1649\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:671\u001b[0m, in \u001b[0;36mClauseElement._compile_w_cache\u001b[1;34m(self, dialect, compiled_cache, column_keys, for_executemany, schema_translate_map, **kw)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mif\u001b[39;00m compiled_sql \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     cache_hit \u001b[39m=\u001b[39m dialect\u001b[39m.\u001b[39mCACHE_MISS\n\u001b[1;32m--> 671\u001b[0m     compiled_sql \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compiler(\n\u001b[0;32m    672\u001b[0m         dialect,\n\u001b[0;32m    673\u001b[0m         cache_key\u001b[39m=\u001b[39;49melem_cache_key,\n\u001b[0;32m    674\u001b[0m         column_keys\u001b[39m=\u001b[39;49mcolumn_keys,\n\u001b[0;32m    675\u001b[0m         for_executemany\u001b[39m=\u001b[39;49mfor_executemany,\n\u001b[0;32m    676\u001b[0m         schema_translate_map\u001b[39m=\u001b[39;49mschema_translate_map,\n\u001b[0;32m    677\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw,\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m     compiled_cache[key] \u001b[39m=\u001b[39m compiled_sql\n\u001b[0;32m    680\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:288\u001b[0m, in \u001b[0;36mCompilerElement._compiler\u001b[1;34m(self, dialect, **kw)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    287\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ClauseElement)\n\u001b[1;32m--> 288\u001b[0m \u001b[39mreturn\u001b[39;00m dialect\u001b[39m.\u001b[39;49mstatement_compiler(dialect, \u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\compiler.py:1424\u001b[0m, in \u001b[0;36mSQLCompiler.__init__\u001b[1;34m(self, dialect, statement, cache_key, column_keys, for_executemany, linting, **kwargs)\u001b[0m\n\u001b[0;32m   1421\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtruncated_names: Dict[Tuple[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[0;32m   1422\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncated_counters: Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1424\u001b[0m Compiled\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, dialect, statement, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misinsert \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misupdate \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misdelete:\n\u001b[0;32m   1427\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\compiler.py:865\u001b[0m, in \u001b[0;36mCompiled.__init__\u001b[1;34m(self, dialect, statement, schema_translate_map, render_schema_translate, compile_kwargs)\u001b[0m\n\u001b[0;32m    863\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(statement, Executable)\n\u001b[0;32m    864\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecution_options \u001b[39m=\u001b[39m statement\u001b[39m.\u001b[39m_execution_options\n\u001b[1;32m--> 865\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstring \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstatement, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcompile_kwargs)\n\u001b[0;32m    867\u001b[0m \u001b[39mif\u001b[39;00m render_schema_translate:\n\u001b[0;32m    868\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstring \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreparer\u001b[39m.\u001b[39m_render_schema_translates(\n\u001b[0;32m    869\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstring, schema_translate_map\n\u001b[0;32m    870\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\compiler.py:910\u001b[0m, in \u001b[0;36mCompiled.process\u001b[1;34m(self, obj, **kwargs)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m, obj: Visitable, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 910\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49m_compiler_dispatch(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\visitors.py:143\u001b[0m, in \u001b[0;36mVisitable._generate_compiler_dispatch.<locals>._compiler_dispatch\u001b[1;34m(self, visitor, **kw)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[39mreturn\u001b[39;00m visitor\u001b[39m.\u001b[39mvisit_unsupported_compilation(\u001b[39mself\u001b[39m, err, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)  \u001b[39m# type: ignore  # noqa: E501\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\compiler.py:5644\u001b[0m, in \u001b[0;36mSQLCompiler.visit_insert\u001b[1;34m(self, insert_stmt, visited_bindparam, **kw)\u001b[0m\n\u001b[0;32m   5641\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_visiting_cte:\n\u001b[0;32m   5642\u001b[0m         visited_bindparam \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 5644\u001b[0m crud_params_struct \u001b[39m=\u001b[39m crud\u001b[39m.\u001b[39;49m_get_crud_params(\n\u001b[0;32m   5645\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   5646\u001b[0m     insert_stmt,\n\u001b[0;32m   5647\u001b[0m     compile_state,\n\u001b[0;32m   5648\u001b[0m     toplevel,\n\u001b[0;32m   5649\u001b[0m     visited_bindparam\u001b[39m=\u001b[39;49mvisited_bindparam,\n\u001b[0;32m   5650\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw,\n\u001b[0;32m   5651\u001b[0m )\n\u001b[0;32m   5653\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional \u001b[39mand\u001b[39;00m visited_bindparam \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5654\u001b[0m     counted_bindparam \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(visited_bindparam)\n",
      "File \u001b[1;32mc:\\Users\\mrosen44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sqlalchemy\\sql\\crud.py:335\u001b[0m, in \u001b[0;36m_get_crud_params\u001b[1;34m(compiler, stmt, compile_state, toplevel, **kw)\u001b[0m\n\u001b[0;32m    329\u001b[0m     check \u001b[39m=\u001b[39m (\n\u001b[0;32m    330\u001b[0m         \u001b[39mset\u001b[39m(parameters)\n\u001b[0;32m    331\u001b[0m         \u001b[39m.\u001b[39mintersection(_column_as_key(k) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m stmt_parameter_tuples)\n\u001b[0;32m    332\u001b[0m         \u001b[39m.\u001b[39mdifference(check_columns)\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m     \u001b[39mif\u001b[39;00m check:\n\u001b[1;32m--> 335\u001b[0m         \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mCompileError(\n\u001b[0;32m    336\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnconsumed column names: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    337\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (c,) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m check))\n\u001b[0;32m    338\u001b[0m         )\n\u001b[0;32m    340\u001b[0m is_default_metavalue_only \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    343\u001b[0m     _compile_state_isinsert(compile_state)\n\u001b[0;32m    344\u001b[0m     \u001b[39mand\u001b[39;00m compile_state\u001b[39m.\u001b[39m_has_multi_parameters\n\u001b[0;32m    345\u001b[0m ):\n\u001b[0;32m    346\u001b[0m     \u001b[39m# is a multiparams, is not an insert from a select\u001b[39;00m\n",
      "\u001b[1;31mCompileError\u001b[0m: Unconsumed column names: sd1/sd2"
     ]
    }
   ],
   "source": [
    "# Get summary cardiac measures\n",
    "do_summative = True\n",
    "do_rolling = False\n",
    "for idx,row in task_list_df.iterrows():\n",
    "    print(str(row['task_num'])+\" \"+row['e4_id']+'...')\n",
    "\n",
    "    try:\n",
    "        # get ibi data    print(t_name)\n",
    "        t = sa.Table(row['e4_id'].lower()+'_bvp', metadata_obj, autoload_with=engine)\n",
    "        if project == 'picu':\n",
    "            s = sa.select(t).where(\n",
    "                sa.and_(\n",
    "                t.c.time_stamp > row['start_time'], \n",
    "                t.c.time_stamp < row['start_time']+pd.Timedelta(4,unit='hours')))\n",
    "        elif project == 'hera':\n",
    "            s = sa.select(t).where(\n",
    "                sa.and_(\n",
    "                t.c.time_stamp > row['start_time'], \n",
    "                t.c.time_stamp < row['start_time']+pd.Timedelta(row['duration_min'],unit='minutes')))\n",
    "        with engine.begin() as conn:\n",
    "            rp = conn.execute(s)\n",
    "            bvp_df = pd.DataFrame(rp.fetchall())\n",
    "            if not bvp_df.empty:\n",
    "                bvp_df.columns = rp.keys()\n",
    "                print(len(bvp_df))\n",
    "                raw_ibi_row_cnt = len(bvp_df)\n",
    "                # process bvp data\n",
    "                if do_summative: # creates one set of values for each timeblock / task\n",
    "                    filtered = filter_bvp(bvp_df.bvp.values)\n",
    "                    wd,m = hp.process(filtered, sample_rate = 64, high_precision = True, high_precision_fs = 1000.0, clean_rr = True)\n",
    "                    m.update({\n",
    "                        'study_member_id':row['e4_id'].lower(), \n",
    "                        'task_num':row['task_num'],\n",
    "                        'raw_ibi_row_cnt':raw_ibi_row_cnt})\n",
    "                    # push to db\n",
    "                    t = sa.Table(\"cardiac_ind_summary\", metadata_obj, autoload_with=engine)\n",
    "                    s = sa.insert(t).values(m)\n",
    "                    conn.execute(s)\n",
    "                    conn.commit()\n",
    "                    # save figs for QC\n",
    "                    #lab = 'task_num_'+str(row['task_num'])+'_'+row['e4_id'].lower()\n",
    "                    #hp.plotter(wd,m, figsize = (12,6),title = lab, show=False).savefig('bvp_plots/'+lab+'.png')\n",
    "                    #hp.plot_poincare(wd,m, title = lab, show=False).savefig('bvp_plots/'+lab+'poincare.png')\n",
    "                if do_rolling: # creates values at 30 second intervals (with a 1 min window)\n",
    "                    print('Doing rolling... '+row['e4_id'].lower())\n",
    "                    wd,m = hp.process_segmentwise(bvp_df.bvp.values,sample_rate = 64, segment_width = 60, \n",
    "                                                    segment_overlap = .5, replace_outliers = True, \n",
    "                                                    outlier_method = 'iqr', mode = 'full')\n",
    "                    m = pd.DataFrame.from_dict(m)\n",
    "                    m['start_ix'], m['end_ix'] = zip(*m.segment_indices)\n",
    "                    m['time_stamp'] = m.end_ix.map(dict(zip(bvp_df.index,bvp_df.time_stamp)))\n",
    "                    m['sdsd'] = m.sdsd.astype('float')\n",
    "                    m.drop(['start_ix','end_ix','segment_indices'], axis=1, inplace=True)\n",
    "                    dtype_dict = {\n",
    "                        'ibi':sa.types.FLOAT(),\n",
    "                        'sdnn': sa.types.FLOAT(),\n",
    "                        'sdsd': sa.types.FLOAT(),\n",
    "                        'rmssd': sa.types.FLOAT(),\n",
    "                        'pnn20': sa.types.FLOAT(),\n",
    "                        'pnn50': sa.types.FLOAT(),\n",
    "                        'hr_mad': sa.types.FLOAT(),\n",
    "                        'sd1':sa.types.FLOAT(),\n",
    "                        'sd2': sa.types.FLOAT(),\n",
    "                        's': sa.types.FLOAT(),\n",
    "                        'sd1/sd2': sa.types.FLOAT(),\n",
    "                        'breathingrate': sa.types.FLOAT(),\n",
    "                        'time_stamp': sa.types.TIMESTAMP(timezone=True)\n",
    "                    }\n",
    "                    m.to_sql(name=row['e4_id'].lower()+'_hpy_rolling',\n",
    "                        con = conn,\n",
    "                        if_exists = 'append',\n",
    "                        index = False,\n",
    "                        dtype = dtype_dict,\n",
    "                        method = 'multi')\n",
    "    except:\n",
    "        print('Problem with... '+'task_num_'+str(row['task_num'])+'_'+row['e4_id'].lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
